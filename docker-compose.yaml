version: "3.9"
services:

  ###### name service ######
  # (note: you can create multiple)
  gstdocker_service_master:

    #### name image  & container ####
    image: ${CONTAINER_NAME}_img
    container_name: ${CONTAINER_NAME}

    #### command to keep container alive ####
    # copied into /usr/local/bin on build
    # command: custom_starting_script.sh ${ENABLE_SSH}
    command: tail -F /dev/null

    #### build Dockerfile and pass build args ####
    build:
      context: .
      dockerfile: Dockerfile

    #### volumes and mappings ####
    volumes:
      ## volumes ##
      # - root:/root/
      # - consider adding the .engine models here after conversion for saving time on launch

      ## mappings ##
      - /tmp/.X11-unix/:/tmp/.X11-unix # x11
      - ~/.ssh:/root/.ssh:ro # ssh folder from linux host
      
      ## development folder mappings here ##
      - ./TCP:${WORKDIR}/TCP
      - ./database:${WORKDIR}/database

    #### environmental variables to set inside the container ####
    # environment:
    #   - DISPLAY=$DISPLAY
    #   PATH_ADD: /opt/nvidia/deepstream/deepstream-6.0/bin # you can append this to bashrc using dockerfile
      
    
    #### priveleged gains access to all devices on host ####
    # good for running docker inside docker if you need. also owning devices like /dev/video0
    # privileged: true 

    #### configure docker network mode ####
    # network_mode: "host" # uses host network stack
    
    #### runtime libraries ####
    # runtime: nvidia
    
    #### start container on boot ####
    # restart: always

    #### container directory to start in ####
    # working_dir: ${WORKDIR}/sources/apps/sample_apps/deepstream_pose_estimation
    working_dir: ${WORKDIR}
    
#### create volumes here ####
# volumes:
#   root:
#   maybe this for .engine files? /opt/nvidia/deepstream/deepstream-6.0/samples/models/ 